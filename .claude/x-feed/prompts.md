# @godofprompt Prompt Feed

Prompts fetched from [@godofprompt](https://x.com/godofprompt) for Claude self-improvement.
Sorted by engagement score (higher = more validated by community).

---

## Seed Prompts (web-searched 2026-02-11)

### [2026-02-11] prompting, ai_tools | engagement: high
XML tags act as semantic boundaries for Claude, not just formatting. Claude treats outer tags as high-level intent and nested tags as execution details. Users report up to 39% improvement in response quality using XML-structured prompts. Combine XML tags with multishot prompting (`<examples>`) or chain of thought (`<thinking>`, `<answer>`).
*Source: [x.com/godofprompt/status/2010649616262304049](https://x.com/godofprompt/status/2010649616262304049)*

### [2026-02-11] prompting, reasoning | engagement: high
Extended Thinking lets Claude reason through problems before answering. Cognition AI reported an 18% increase in planning performance. For complex tasks, enable Extended Thinking and let the model work through the problem space before committing to an answer.
*Source: [x.com/godofprompt/status/2010649616262304049](https://x.com/godofprompt/status/2010649616262304049)*

### [2026-02-11] prompting, reasoning | engagement: high
"Think step by step" makes the model slow down and reason before answering. Accuracy jumps. Tree-of-Thought lets it consider multiple options before deciding - great for planning or strategy. ReAct makes it switch between thinking and searching, with more complete and fact-checked results.
*Source: [x.com/godofprompt/status/1953959797763478015](https://x.com/godofprompt/status/1953959797763478015)*

### [2026-02-11] prompting, ai_tools | engagement: high
Claude best practices: Use first principles decomposition for complex problems. Structure prompts as Role + Vibe + Goal + Constraints + Output Format. One prompt = one job. If you need more, break it into steps. Claude shines when you guide it step-by-step.
*Source: [godofprompt.ai/blog/20-best-claude-ai-prompts](https://www.godofprompt.ai/blog/20-best-claude-ai-prompts)*

### [2026-02-11] prompting, meta | engagement: high
The Consultant Framework Mega Prompt: "You are a world-class strategy consultant trained by McKinsey, BCG, and Bain. Act as if you were hired to provide a $300,000 strategic analysis for a client in the [INDUSTRY] sector." - Role elevation forces higher quality reasoning.
*Source: [x.com/godofprompt/status/1934636234305048917](https://x.com/godofprompt/status/1934636234305048917)*

### [2026-02-11] prompting, meta | engagement: high
Use systematic step-by-step process and self-correction via Tree of Thoughts for complex queries. Complex prompt frameworks still work, but modern models understand context so well that plain language is often better. Match complexity to the task.
*Source: [x.com/godofprompt/status/1963421658581971023](https://x.com/godofprompt/status/1963421658581971023)*

### [2026-02-11] prompting, productivity | engagement: medium
Drop a mini example inside your prompt - even a simple 1-2 line example helps Claude lock in on your style fast. Always set the tone explicitly. Test small changes - tweak your prompt 2-3 different ways. Best outputs usually come after a little prompt testing.
*Source: [godofprompt.ai/blog/20-best-claude-ai-prompts](https://www.godofprompt.ai/blog/20-best-claude-ai-prompts)*

### [2026-02-11] prompting, productivity | engagement: medium
NotebookLM prompts that went viral: 16 copy-paste prompts that turned a "cool AI toy" into a research weapon doing 10 hours of work in 20 seconds. The key insight: structured prompts with clear output formats dramatically compress research time.
*Source: [x.com/godofprompt/status/2008938090950475816](https://x.com/godofprompt/status/2008938090950475816)*

---
